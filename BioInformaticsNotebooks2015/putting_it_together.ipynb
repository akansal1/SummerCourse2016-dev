{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#Installation Part 1\n",
    "We need to install demultiplexing software.  We will get that started now so that it can run while we are doing other things\n",
    "\n",
    "1. Open a jupyter terminal\n",
    "    1. click on the jupyter *File* menu, and select *Open*.  \n",
    "    2. A new browser window/tab should open, with your jupyter *home base*. Here, you should click on the *Files* tab if it is not already active\n",
    "    3. Now click on *New* and select *Terminal*, which should open a new live terminal.\n",
    "2. `cd ~/bioinf_nb_ngscourse2015`\n",
    "3. `git pull`\n",
    "4. `sudo bash install_fastq_multx.sh` # you will need to enter your password from vm-manage\n",
    "5. When the installation is done, you can confirm that it worked by running `fastq-multx`, which should print help information for running the program."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "cd ~/bioinf_1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#More FASTQs\n",
    "So far we have only been working with one FASTQ, but eventually we will want to work with all our data.  Let's set up a directory with links to all of our FASTQ files.  The `*.gz`  in the `ln -s` command means to make a link for each file in that directory that end in `.gz`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "%%bash\n",
    "mkdir -p fastqs\n",
    "ln -s /home/bitnami/test_run_data/demux_2mismatch/*.gz fastqs/"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "ls fastqs/"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#Working with Paired-Reads\n",
    "So far we have only been working with a single read file, but we have paired-end read data.  If we want to use both reads, we need to do things a little bit different at some of the steps.\n",
    "\n",
    "## Running fastq-mcf on Paired Data\n",
    "It only takes two minor changes to run fastq-mcf on paired data, we need to tell it to also load the R2 file, and what to call the trimmed output from this file. \n",
    "\n",
    "1. neb_19_adapter.fasta \n",
    "2. fastqs/r1.GTGAAA.fastq.gz : Note we are using the original file name\n",
    "2. fastqs/r2.GTGAAA.fastq.gz : NEW for paired-data\n",
    "3. -q 20\n",
    "4. -x 0.5\n",
    "5. -o fastqs/r1.GTGAAA.trim.fastq.gz\n",
    "6. -o fastqs/r2.GTGAAA.trim.fastq.gz\n",
    "\n",
    "Let's make a directory to put the trimmed FASTQs in, then run the whole thing."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "%%bash\n",
    "mkdir -p trimmed\n",
    "fastq-mcf neb_19_adapter.fasta \\\n",
    "    fastqs/r1.GTGAAA.fastq.gz \\\n",
    "    fastqs/r2.GTGAAA.fastq.gz \\\n",
    "    -q 20 -x 0.5 \\\n",
    "    -o trimmed/r1.GTGAAA.trim.fastq.gz \\\n",
    "    -o trimmed/r2.GTGAAA.trim.fastq.gz"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "ls fastqs"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Running Tophat on Paired Data\n",
    "As with fastq-mcf, running Tophat on Paired Data on requires a minor change - adding the R2 file as an input; of course we will want to save the results to a different output directory."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "%%bash\n",
    "mkdir -p th_out/GTGAAA\n",
    "tophat2 -G genome/ecoli_w3110.gff \\\n",
    "    --library-type fr-firststrand \\\n",
    "    --output-dir th_out/GTGAAA \\\n",
    "    --max-intron-length 5 \\\n",
    "    --min-intron-length 4 \\\n",
    "    --transcriptome-max-hits 1 \\\n",
    "    --max-multihits 1 \\\n",
    "    --no-coverage-search \\\n",
    "    --no-novel-juncs \\\n",
    "    --num-threads 2 \\\n",
    "    genome/ecoli_w3110 \\\n",
    "    trimmed/r1.GTGAAA.trim.fastq.gz \\\n",
    "    trimmed/r2.GTGAAA.trim.fastq.gz"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Running htseq-count on Paired Data\n",
    "We have to do one thing different to run htseq-count on paired data. The BAM file output by tophat will contain both reads for each spot, but by default htseq-count expects the two reads in a pair to be right next to each other in the BAM file.  By default Tophat sorts the BAM by the read's position in the genome.  We can tell htseq-count to expect this using the `--order=pos` option, but it sometimes doesn't like tophat's sorting, so it is best if we just sort it ourselves by name, and for good measure we will explicitly tell htseq-count that is what we have done with `--order=pos`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "%%bash\n",
    "samtools sort -n th_out/GTGAAA/accepted_hits.bam \\\n",
    "    th_out/GTGAAA/accepted_hits.name\n",
    "htseq-count --quiet --order=name --format=bam --stranded=reverse \\\n",
    "    --type=gene --idattr=ID \\\n",
    "    th_out/GTGAAA/accepted_hits.name.bam \\\n",
    "    genome/ecoli_w3110.gff > counts/GTGAAA.csv"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#Working with Multiple Samples\n",
    "Let's kick it up another notch - we have six samples, let's run our analysis on all of them!  First let's run fastqc on everything.  This is very easy, we can just give it all the FASTQ files on the command line, and it runs on all of them.  We can use the wildcard `*` to do this simply."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "%%bash\n",
    "mkdir -p qc_output\n",
    "fastqc --threads 2 --quiet --outdir qc_output fastqs/*.fastq.gz"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## A Brief journey into for loops\n",
    "Most of the steps in our pipeline aren't so simple.  To apply our pipeline to multiple sample files, we need to change things in multiple places.  For example, just to run Tophat, we need to change things in four places between each run, the output directory name (twice) and the name of the FASTQ.  Doing this by hand is not only tedious, but error prone.  Doing almost the same thing repeatedly is something that computers are very good at, and people are very bad at, so let's get the computer to do the hard work.  Because the Unix shell is almost magical (it is a full fledged programming language), we can do this.  We will use a `for loop`.  This is analogous to how you would teach a child to set the table: \"FOR each place at the table, put a plate . . .,\n",
    "At the shell you phrase it like this:\n",
    "\n",
    "    for PERSON in Alice Bob Carol Dave Eve\n",
    "    do\n",
    "    put plate at PERSON's place\n",
    "    put napkin at PERSON's place\n",
    "    put fork at PERSON's place\n",
    "    put spoon at PERSON's place\n",
    "    put knife at PERSON's place\n",
    "    done\n",
    "\n",
    "Here is a real example:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "%%bash\n",
    "for SAMPLE in A B C D E F\n",
    "    do\n",
    "       echo XXXXX_${SAMPLE}_XXXXX \n",
    "    done"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "the `do` and `done` are essential - `do` needs to be before the \"loop body\" (what is going to be repeated) and `done` needs to be after it.\n",
    "\n",
    "So let's try something almost useful:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "%%bash\n",
    "for BARCODE in GTGAAA\n",
    "    do\n",
    "        echo $BARCODE\n",
    "    done"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "###Let's run fastq-mcf in a loop:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "%%bash\n",
    "mkdir -p trimmed\n",
    "\n",
    "for BARCODE in GTGAAA\n",
    "    do\n",
    "        echo $BARCODE\n",
    "        fastq-mcf neb_19_adapter.fasta \\\n",
    "            fastqs/r1.${BARCODE}.fastq.gz \\\n",
    "            fastqs/r2.${BARCODE}.fastq.gz \\\n",
    "            -q 20 -x 0.5 \\\n",
    "            -o trimmed/r1.${BARCODE}.trim.fastq.gz \\\n",
    "            -o trimmed/r2.${BARCODE}.trim.fastq.gz\n",
    "    done"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "###Now let's do the same thing for tophat"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "%%bash\n",
    "for BARCODE in GTGAAA\n",
    "    do\n",
    "        echo $BARCODE\n",
    "        mkdir -p th_out/${BARCODE}\n",
    "        tophat2 -G genome/ecoli_w3110.gff \\\n",
    "            --library-type fr-firststrand \\\n",
    "            --output-dir th_out/${BARCODE} \\\n",
    "            --max-intron-length 5 \\\n",
    "            --min-intron-length 4 \\\n",
    "            --transcriptome-max-hits 1 \\\n",
    "            --max-multihits 1 \\\n",
    "            --no-coverage-search \\\n",
    "            --no-novel-juncs \\\n",
    "            --num-threads 2 \\\n",
    "            genome/ecoli_w3110 \\\n",
    "            trimmed/r1.${BARCODE}.trim.fastq.gz \\\n",
    "            trimmed/r2.${BARCODE}.trim.fastq.gz\n",
    "    done"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "###And now for htseq-count!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "%%bash\n",
    "for BARCODE in GTGAAA\n",
    "    do\n",
    "        echo $BARCODE\n",
    "        samtools sort -n th_out/${BARCODE}/accepted_hits.bam \\\n",
    "            th_out/${BARCODE}/accepted_hits.name\n",
    "\n",
    "        htseq-count --quiet --order=name --format=bam --stranded=reverse \\\n",
    "            --type=gene --idattr=ID \\\n",
    "            th_out/${BARCODE}/accepted_hits.name.bam \\\n",
    "            genome/ecoli_w3110.gff > counts/${BARCODE}.csv\n",
    "    done"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "###Now Everything Together!!\n",
    "We will now run all the samples, but first we need to generate an adapter file for all the samples. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Generating a full adapter file\n",
    "We still need to do the copy-and-paste part from the index primer manual, but we will do the reverse complementing automatically.  Let's do that now (if you are feeling lazy, you can use the `testrun_adapters.fasta` file in the repo directory) . . .\n",
    "\n",
    "OK, now that it is out of the way, we need to install a python library that our reverse complementing script will use"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "%%bash\n",
    "pip install biopython"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now we can run our script.  By default it only outputs the reverse complemented sequences, but with the --both option, it will also output the original sequence."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "%%bash\n",
    "~/bioinf_nb_ngscourse2015/revcomp.py \\\n",
    "    ~/bioinf_nb_ngscourse2015/testrun_adapters.fasta \\\n",
    "    --both --output testrun_adapters_both.fasta"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "####Looping over all the samples\n",
    "Now we can put all of the previous commands into one big loop.  This is probably a good time for copying and pasting.  But we will make a few small changes.\n",
    "\n",
    "1. We will add all the barcodes the the list of barcodes to iterate over\n",
    "    * AGTCAA AGTTCC ATGTCA CCGTCC GTCCGC GTGAAA\n",
    "2. We need to remember to use our full adapter file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "%%bash\n",
    "mkdir -p trimmed\n",
    "mkdir -p th_out\n",
    "mkdir -p counts\n",
    "\n",
    "for BARCODE in AGTCAA AGTTCC ATGTCA CCGTCC GTCCGC GTGAAA\n",
    "    do\n",
    "        echo $BARCODE\n",
    "        fastq-mcf testrun_adapters_both.fasta \\\n",
    "            fastqs/r1.${BARCODE}.fastq.gz \\\n",
    "            fastqs/r2.${BARCODE}.fastq.gz \\\n",
    "            -q 20 -x 0.5 \\\n",
    "            -o trimmed/r1.${BARCODE}.trim.fastq.gz \\\n",
    "            -o trimmed/r2.${BARCODE}.trim.fastq.gz\n",
    "            \n",
    "        mkdir -p th_out/${BARCODE}\n",
    "        tophat2 -G genome/ecoli_w3110.gff \\\n",
    "            --library-type fr-firststrand \\\n",
    "            --output-dir th_out/${BARCODE} \\\n",
    "            --max-intron-length 5 \\\n",
    "            --min-intron-length 4 \\\n",
    "            --transcriptome-max-hits 1 \\\n",
    "            --max-multihits 1 \\\n",
    "            --no-coverage-search \\\n",
    "            --no-novel-juncs \\\n",
    "            --num-threads 2 \\\n",
    "            genome/ecoli_w3110 \\\n",
    "            trimmed/r1.${BARCODE}.trim.fastq.gz \\\n",
    "            trimmed/r2.${BARCODE}.trim.fastq.gz\n",
    "            \n",
    "        ln th_out/${BARCODE}/accepted_hits.bam th_out/${BARCODE}.bam\n",
    "        samtools index th_out/${BARCODE}.bam\n",
    "        \n",
    "        samtools sort -n th_out/${BARCODE}/accepted_hits.bam \\\n",
    "            th_out/${BARCODE}/accepted_hits.name\n",
    "\n",
    "        htseq-count --quiet --order=name --format=bam --stranded=reverse --type=gene \\\n",
    "            --idattr=ID th_out/${BARCODE}/accepted_hits.name.bam \\\n",
    "            genome/ecoli_w3110.gff > counts/${BARCODE}.csv\n",
    "    done"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "ls th_out/"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
